# TÃºlioAI

<div align="center">

ğŸ“ **Assistente de Estudos baseado em IA e RAG (Retrieval-Augmented Generation)**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

## ğŸ“‹ Sobre

TÃºlioAI Ã© um assistente de estudos inteligente que responde perguntas com base em documentos Markdown usando RAG (Retrieval-Augmented Generation).

## ğŸš€ Quick Start

```bash
# 1. Clone e entre no diretÃ³rio
git clone https://github.com/thinkmadu/TutorAI.git && cd TutorAI

# 2. Execute o setup automÃ¡tico
python3 setup_env.py
```

O script configura ambiente virtual, dependÃªncias, FAISS e inicia a interface escolhida. ğŸ‰

## âœ¨ CaracterÃ­sticas

- ğŸ” **Busca Vetorial**: FAISS para recuperaÃ§Ã£o rÃ¡pida e precisa
- ğŸ§  **LLM Local**: Modelos HuggingFace (TinyLlama, Mistral, etc.)
- ğŸ’» **Dupla Interface**: CLI (terminal) e Streamlit (web)
- ğŸ—ï¸ **Clean Architecture**: DomÃ­nio, serviÃ§os e infraestrutura separados
- ğŸ“š **Base PersonalizÃ¡vel**: Indexe seus prÃ³prios arquivos Markdown

## ğŸ—ï¸ Arquitetura

```
tulioai/
â”œâ”€â”€ main.py                    # Ponto de entrada
â”œâ”€â”€ setup_env.py               # ConfiguraÃ§Ã£o automÃ¡tica
â”œâ”€â”€ create_faiss_index.py      # CriaÃ§Ã£o do Ã­ndice vetorial
â”œâ”€â”€ core/                      # DomÃ­nio (entities, rules)
â”œâ”€â”€ services/                  # AplicaÃ§Ã£o (rag_service)
â”œâ”€â”€ infrastructure/            # Adapters (loaders, retrievers, generators)
â”œâ”€â”€ interfaces/                # CLI e Streamlit
â””â”€â”€ data/
    â””â”€â”€ knowledge_base/        # Seus arquivos .md
```

## ï¿½ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: AutomÃ¡tica (Recomendado)

```bash
python3 setup_env.py
```

O script automaticamente:
- âœ… Cria ambiente virtual
- âœ… Instala dependÃªncias
- âœ… Configura `.env`
- âœ… Verifica/cria banco FAISS
- âœ… Inicia interface escolhida

### OpÃ§Ã£o 2: Manual

```bash
# Ambiente virtual
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# DependÃªncias
pip install -r requirements.txt

# ConfiguraÃ§Ã£o
cp .env.example .env  # Edite conforme necessÃ¡rio

# Ãndice FAISS
python create_faiss_index.py

# Iniciar
python main.py --interface cli
```

## ğŸ“– Uso

### 1. Adicionar Documentos

```bash
# Adicione seus arquivos .md
cp seus_documentos/*.md data/knowledge_base/

# Reindexe
python create_faiss_index.py
```

### 2. Fazer Perguntas

**Interface CLI:**
```bash
python main.py --interface cli
```

**Interface Web:**
```bash
python main.py --interface streamlit
# Acesse http://localhost:8501
```

## âš™ï¸ ConfiguraÃ§Ã£o

### Arquivo `.env`

```env
# Ãndice FAISS
FAISS_PATH=./models/faiss_index_tutorai

# Embeddings (HuggingFace)
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# LLM (HuggingFace)
LLM_MODEL=TinyLlama/TinyLlama-1.1B-Chat-v1.0

# Hardware
DEVICE=cpu  # ou cuda para GPU

# GeraÃ§Ã£o
TEMPERATURE=0.1
MAX_NEW_TOKENS=512
TOP_K_RETRIEVAL=4

# Dados
KNOWLEDGE_BASE_PATH=./data/knowledge_base
```

### Modelos Recomendados

**Embeddings:**
- `sentence-transformers/all-MiniLM-L6-v2` (padrÃ£o, 80MB)
- `sentence-transformers/all-mpnet-base-v2` (melhor, 420MB)

**LLM:**
- `TinyLlama/TinyLlama-1.1B-Chat-v1.0` (padrÃ£o, 1.1GB)
- `mistralai/Mistral-7B-Instruct-v0.2` (melhor, 7GB)

### GPU (CUDA)

```bash
# Instale PyTorch com CUDA
pip install torch --index-url https://download.pytorch.org/whl/cu118

# Instale FAISS-GPU
pip uninstall faiss-cpu && pip install faiss-gpu

# Configure .env
DEVICE=cuda
```

## ğŸ› Troubleshooting

| Problema | SoluÃ§Ã£o |
|----------|---------|
| Ãndice FAISS nÃ£o encontrado | `python create_faiss_index.py` |
| Out of memory | Use modelo menor (TinyLlama) ou reduza `MAX_NEW_TOKENS` |
| Respostas ruins | Aumente `TOP_K_RETRIEVAL` ou melhore documentos |
| IndexaÃ§Ã£o lenta | Use GPU ou reduza tamanho dos chunks |
| Erro de importaÃ§Ã£o | `pip install --upgrade -r requirements.txt` |

## â“ FAQ

<details>
<summary><b>Preciso rodar setup_env.py toda vez?</b></summary>

NÃ£o! Execute apenas na primeira instalaÃ§Ã£o. Depois use `python main.py --interface cli/streamlit`.
</details>

<details>
<summary><b>Quando recriar o Ã­ndice FAISS?</b></summary>

Sempre que adicionar/modificar documentos ou trocar modelo de embeddings:
```bash
python create_faiss_index.py
```
</details>

<details>
<summary><b>Posso usar GPU?</b></summary>

Sim! Se tem GPU NVIDIA:
1. Instale PyTorch com CUDA
2. Instale `faiss-gpu`
3. Configure `DEVICE=cuda` no `.env`
</details>

<details>
<summary><b>Qual modelo Ã© melhor?</b></summary>

Depende do hardware:
- **TinyLlama** (1.1GB): RÃ¡pido, qualquer PC
- **Mistral-7B** (7GB): Melhor qualidade, precisa 16GB+ RAM
</details>

<details>
<summary><b>Como limpar instalaÃ§Ã£o?</b></summary>

```bash
rm -rf .venv .env models/ logs/
# Mantenha data/ se tiver documentos importantes
```
</details>

## ï¿½ Fluxo RAG

```
Pergunta â†’ Embedding â†’ Busca FAISS (Top-K) â†’ Contexto â†’ LLM â†’ Resposta + Fontes
```

## ğŸ› ï¸ Desenvolvimento

```bash
# Testes
pytest tests/

# FormataÃ§Ã£o
black . && isort . && flake8 .
```

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie branch: `git checkout -b feature/MinhaFeature`
3. Commit: `git commit -m 'Add MinhaFeature'`
4. Push: `git push origin feature/MinhaFeature`
5. Abra Pull Request

## ğŸ“ LicenÃ§a

MIT License - veja [LICENSE](LICENSE)

## ğŸ™ Agradecimentos

- [HuggingFace](https://huggingface.co/) - Modelos e Transformers
- [FAISS](https://github.com/facebookresearch/faiss) - Busca vetorial
- [Sentence Transformers](https://www.sbert.net/) - Embeddings
- [Streamlit](https://streamlit.io/) - Interface web

---

<div align="center">
Feito com â¤ï¸ e â˜•
</div>
